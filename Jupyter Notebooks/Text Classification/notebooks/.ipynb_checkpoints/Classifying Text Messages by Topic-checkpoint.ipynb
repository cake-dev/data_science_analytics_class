{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 20 newsgroups dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [20 Newsgroups data set](http://qwone.com/~jason/20Newsgroups/) is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups.\n",
    "The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic:\n",
    "\n",
    "- 'atheism',\n",
    "- 'comp.graphics',\n",
    "- 'comp.os.ms-windows.misc',\n",
    "- 'comp.sys.ibm.pc.hardware',\n",
    "- 'comp.sys.mac.hardware',\n",
    "- 'comp.windows.x',\n",
    "- 'misc.forsale',\n",
    "- 'rec.autos',\n",
    "- 'rec.motorcycles',\n",
    "- 'rec.sport.baseball',\n",
    "- 'rec.sport.hockey',\n",
    "- 'sci.crypt',\n",
    "- 'sci.electronics',\n",
    "- 'sci.med',\n",
    "- 'sci.space',\n",
    "- 'soc.religion.christian',\n",
    "- 'talk.politics.guns',\n",
    "- 'talk.politics.mideast',\n",
    "- 'talk.politics.misc',\n",
    "- 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we will work on a partial dataset with only 6 categories out of the 20 available in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose, for example, 6 categories\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'comp.windows.x',\n",
    "    'rec.autos',\n",
    "    'rec.sport.baseball',\n",
    "    'sci.electronics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', \n",
    "                                categories=categories,\n",
    "                                remove=('headers', 'footers', 'quotes')\n",
    "                          )\n",
    "\n",
    "test = fetch_20newsgroups(subset='test', \n",
    "                                categories=categories,\n",
    "                                remove=('headers', 'footers', 'quotes')\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benedikt Rosenau writes, with great authority:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nI don't understand this last statement about...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to compile X11r5 on a Sony NWS-1750 r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\nHow do you know it's based on ignorance,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nmuch crap deleted\\n\\n\\nDEAD WRONG!  Last tim...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Benedikt Rosenau writes, with great authority:...         0\n",
       "1  \\nI don't understand this last statement about...         2\n",
       "2  I'd like to compile X11r5 on a Sony NWS-1750 r...         1\n",
       "3  \\n\\n\\nHow do you know it's based on ignorance,...         0\n",
       "4  \\nmuch crap deleted\\n\\n\\nDEAD WRONG!  Last tim...         3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame({'text' : train['data'], \n",
    "                           'category' : train['target']})\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can see it now emblazened across the evening...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The color of the board shows the composition o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regarding the feasability of retrieving the HS...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nI believe Acker got a ring from his wife whe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nThe new Cruisers DO NOT have independent s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  I can see it now emblazened across the evening...         5\n",
       "1  The color of the board shows the composition o...         4\n",
       "2  Regarding the feasability of retrieving the HS...         5\n",
       "3  \\nI believe Acker got a ring from his wife whe...         3\n",
       "4  \\n\\nThe new Cruisers DO NOT have independent s...         2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame({'text' : test['data'], \n",
    "                           'category' : test['target']})\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.windows.x',\n",
       " 'rec.autos',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.electronics',\n",
       " 'sci.space']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    597\n",
       "2    594\n",
       "5    593\n",
       "1    593\n",
       "4    591\n",
       "0    480\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics\n",
    "train_data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    397\n",
       "2    396\n",
       "1    395\n",
       "5    394\n",
       "4    393\n",
       "0    319\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics\n",
    "test_data.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**:  classify documents from the dataset by their topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.text\n",
    "y_train = train_data.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer()), # or CountVectorizer\n",
    "    ('clf', MultinomialNB()) # or LogisticRegression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dic =  {'vect__max_features' : [1000,2000,5000,10000],\n",
    "               'vect__stop_words' : ['english', None],\n",
    "               'vect__min_df' : [5,10,20,50],\n",
    "               'vect__ngram_range' : [(1,1), (1,2),(1,3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vect__max_features': [1000, 2000, 5000, 10000],\n",
       "                         'vect__min_df': [5, 10, 20, 50],\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vect__stop_words': ['english', None]},\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe,params_dic,scoring='accuracy',cv=5, n_jobs=-1, verbose=True)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645653225636819"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_features': 10000,\n",
       " 'vect__min_df': 5,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "X_test = test_data.text\n",
    "y_test = test_data.category\n",
    "y_test_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[235,   9,  20,  19,   4,  32],\n",
       "       [  0, 365,   4,  13,   6,   7],\n",
       "       [  5,   5, 323,  34,  18,  11],\n",
       "       [  8,  10,   7, 366,   5,   1],\n",
       "       [  6,  25,  28,  17, 303,  14],\n",
       "       [ 15,  10,  13,  25,  13, 318]], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.windows.x',\n",
       " 'rec.autos',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.electronics',\n",
       " 'sci.space']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.predict(['I always wanted to be an astronaut','I hate Windows 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf['clf']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read titanic data\n",
    "titanic = pd.read_csv('../../Data/titanic.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical features (non-numeric features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# create ordinal encoder instance\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# fit and transform the data\n",
    "encoder.fit(titanic[['Sex']])\n",
    "\n",
    "# transform the data\n",
    "encoder.transform(titanic[['Sex']]) # male = 0, female = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordinal encoder instance\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# fit and transform the data\n",
    "encoder.fit(titanic[['Sex', 'Embarked']])\n",
    "\n",
    "# transform the data\n",
    "encoder.transform(titanic[['Sex','Embarked']]) # male = 0, female = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature types (non numerical)\n",
    "#### Ordinal: \n",
    "- Categorical features that can be sorted or ordered (e.g. educationnal level: high school, college, graduate school)\n",
    "- Can be encoded as integers (e.g. 0, 1, 2)\n",
    "- The sklearn OrdinalEncoder can be used to encode ordinal features\n",
    "    - it assumes categories are ordered, and the distance between each category is the same\n",
    "\n",
    "#### Nominal:\n",
    "- Categorical feature with no specific order\n",
    "- Cannot be encoded as integers\n",
    "- The sklearn OneHotEncoder can be used to encode nominal features\n",
    "    - it creates a new binary feature for each category\n",
    "    - e.g. if there are 3 categories, it creates 3 binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False) # set sparse to false to get a numpy array (this allows you to see the column names, which is the encoder categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(titanic[['Sex', 'Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform(titanic[['Sex', 'Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Standardization\n",
    "- Normalization: rescaling numerical features to a range of [0, 1]\n",
    "- Standardization: rescaling numerical features to have a mean of 0 and a standard deviation of 1\n",
    "\n",
    "These actions omprove the performance of some machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization with sklearn\n",
    "\n",
    "MinMaxScaler\n",
    "- The MinMaxScaler rescales features to a range of [0, 1]\n",
    "- It is sensitive to outliers\n",
    "- works by subtracting the minimum value and then dividing by the range\n",
    "- when to use: when the distribution of the feature is not Gaussian or when you want to preserve outliers\n",
    "\n",
    "MaxAbsScaler\n",
    "- The MaxAbsScaler rescales features to a range of [-1, 1]\n",
    "- It is sensitive to outliers\n",
    "- works by dividing each value by the maximum absolute value in the feature\n",
    "- when to use: when the distribution of the feature is not Gaussian or when you want to preserve outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization with sklearn\n",
    "\n",
    "StandardScaler\n",
    "- The StandardScaler rescales features to have a mean of 0 and a standard deviation of 1\n",
    "- It is not sensitive to outliers\n",
    "- works by subtracting the mean and then dividing by the standard deviation\n",
    "- when to use: when the distribution of the feature is Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(titanic[['Pclass', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(titanic[['Pclass', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[['Pclass', 'Age', 'Fare']] = scaler.transform(titanic[['Pclass', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation: dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values can be imputed (replaced) with: a constant value, the mean, the median, most frequent value, or a value estimated by a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputer_numeric.fit(titanic[['Age']])\n",
    "imputer_numeric.transform(titanic[['Age']]) # replaces missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer_categorical.fit(titanic[['Embarked']])\n",
    "imputer_categorical.transform(titanic[['Embarked']]) # replaces missing values with the most frequent value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features / Interaction Features\n",
    "\n",
    "Feature forging like this can help a linear model learn non-linear relationships\n",
    "\n",
    "Polynomial Features\n",
    "- Polynomial features are new features created by raising existing features to an exponent\n",
    "- Polynomial features can be created manually or with sklearn PolynomialFeatures\n",
    "- can be different degrees\n",
    "    - d0 = 1 (bias)\n",
    "    - d1 = x (original feature)\n",
    "    - d2 = x^2 (original feature squared)\n",
    "    - d3 = x^3 (original feature cubed)\n",
    "    - ...\n",
    "\n",
    "Interaction Features\n",
    "- Interaction features are new features created by interacting existing features\n",
    "- Interaction features can be created manually or with sklearn PolynomialFeatures\n",
    "- can be different degrees\n",
    "    - d0 = 1 (bias)\n",
    "    - d1 = x (original feature)\n",
    "    - d2 = x*y (original feature multiplied by another feature)\n",
    "    - d3 = x^2*y (original feature squared multiplied by another feature)\n",
    "    - ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where age nan\n",
    "titanic.dropna(subset=['Age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 3.00000000e+00, 2.20000000e+01, ...,\n",
       "        4.84000000e+02, 1.59500000e+02, 5.25625000e+01],\n",
       "       [1.00000000e+00, 1.00000000e+00, 3.80000000e+01, ...,\n",
       "        1.44400000e+03, 2.70876540e+03, 5.08130886e+03],\n",
       "       [1.00000000e+00, 3.00000000e+00, 2.60000000e+01, ...,\n",
       "        6.76000000e+02, 2.06050000e+02, 6.28056250e+01],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.90000000e+01, ...,\n",
       "        3.61000000e+02, 5.70000000e+02, 9.00000000e+02],\n",
       "       [1.00000000e+00, 1.00000000e+00, 2.60000000e+01, ...,\n",
       "        6.76000000e+02, 7.80000000e+02, 9.00000000e+02],\n",
       "       [1.00000000e+00, 3.00000000e+00, 3.20000000e+01, ...,\n",
       "        1.02400000e+03, 2.48000000e+02, 6.00625000e+01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "polyfeat.fit(titanic[['Pclass', 'Age', 'Fare']])\n",
    "polyfeat.transform(titanic[['Pclass', 'Age', 'Fare']]) # degree 2 leads to 10 features (3 original features + 3 squared features + 3 interaction features + 1 bias term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', 'Pclass', 'Age', 'Fare', 'Pclass^2', 'Pclass Age',\n",
       "       'Pclass Fare', 'Age^2', 'Age Fare', 'Fare^2'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get polynomial feature names\n",
    "polyfeat.get_feature_names_out(['Pclass', 'Age', 'Fare'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
